{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    div.output_wrapper {\n",
    "      line-height: 1em; padding: 0;\n",
    "      font-size: 1.2em;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "\n",
    "# Demonstration Informed Specification Search: Experiment\n",
    "\n",
    "Let's take a look at how the DISS algorithm can search for specifications by leveraging expert demonstrations. \n",
    "We'll focus on learning DFAs in this case, but note that this approach is not confined to any specific concept class. To start consider an agent operating in the following stochastic gridworld."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/enter_lava_augmented_1.svg\"\n",
    "         style=\"height: 25em;\"\n",
    "     />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Agent Actions\n",
    "\n",
    "The agent can attempt to move up, down, left, or right as illustrated below.\n",
    "\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/enter_lava_augmented_2.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Transitions\n",
    "\n",
    "However, there is some small probability that the agent will slip downward do to wind!\n",
    "\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/enter_lava_augmented_3.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's assume the agent's task can be described in terms of the color's of the tiles. **What was the agent trying to do?**\n",
    "\n",
    "\n",
    "## Probably avoiding the red tiles\n",
    "\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/enter_lava_augmented_4.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>\n",
    "\n",
    "## Probably trying to reach yellow tile\n",
    "\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/enter_lava_augmented_5.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will illustrate learning task representations (in the form of Deterministic Finite Automata, i.e. DFA) that can be learned incrementally and describe temporal tasks.\n",
    "\n",
    "In particular, we shall consider a variation of the following gridworld from [this](https://mjvc.me/DISS/#/77) slide deck: Here the agent's task is a composition of three subtasks.\n",
    "\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/example_domain_1.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>\n",
    "\n",
    "Where each subtask is a regular language represented as a DFA.\n",
    "\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/example_domain_2_1.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>\n",
    "\n",
    "Further, we shall assume that the first two subtasks are a-priori known (say due to learning in another workspace), \n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/example_domain_1_2.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>\n",
    "\n",
    "and our task is to learn the third task given a partial demonstration.\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/example_domain_3_2.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "import attr\n",
    "import funcy as fn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bidict import bidict\n",
    "from IPython.display import Image, display, SVG\n",
    "import networkx as nx\n",
    "import pydot\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import dfa\n",
    "from dfa.utils import find_subset_counterexample, find_equiv_counterexample\n",
    "from dfa_identify import find_dfa, find_dfas\n",
    "\n",
    "from diss.product_mc import ProductMC\n",
    "from diss.dfa_concept import DFAConcept\n",
    "from diss.domains.gridworld_naive import GridWorldNaive as World\n",
    "from diss.domains.gridworld_naive import GridWorldState as State\n",
    "from diss import search, LabeledExamples, GradientGuidedSampler, ConceptIdException\n",
    "from pprint import pprint\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm.notebook import trange\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import HTML as html_print\n",
    "from functools import reduce\n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's first visualize our gridworld and a demonstration within the gridworld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_ALIAS = {\n",
    "    'white': 'white',\n",
    "    'yellow': '#ffff00', \n",
    "    #'brown': '#ffb081',\n",
    "    'red': '#ff8b8b',\n",
    "    'blue': '#afafff', \n",
    "    'green' : '#8ff45d'\n",
    "}\n",
    "\n",
    "\n",
    "def tile(color='black'):\n",
    "    color = COLOR_ALIAS.get(color, color)\n",
    "    s = '&nbsp;'*4\n",
    "    return f\"<text style='border: solid 1px;background-color:{color}'>{s}</text>\"\n",
    "\n",
    "\n",
    "def ap_at_state(x, y, world):\n",
    "    \"\"\"Use sensor to create colored tile.\"\"\"\n",
    "    if (x, y) in world.overlay:\n",
    "        color = world.overlay[(x,y)]\n",
    "\n",
    "        if color in COLOR_ALIAS.keys():\n",
    "            return tile(color)\n",
    "    return tile('white')\n",
    "\n",
    "def print_map(world):\n",
    "    \"\"\"Scan the board row by row and print colored tiles.\"\"\"\n",
    "    order = range(1, world.dim + 1)\n",
    "    buffer = ''\n",
    "    for y in order:\n",
    "        chars = (ap_at_state(x, y, world) for x in order)\n",
    "        buffer += '&nbsp;'.join(chars) + '<br>'\n",
    "    display(html_print(buffer))\n",
    "\n",
    "def print_trc(trc, world, idx=0):\n",
    "    states = [s for s, kind in trc if kind == 'ego']\n",
    "    actions = [s.action for s, kind in trc if kind == 'env']\n",
    "\n",
    "    obs = [ap_at_state(pos.x, pos.y, world) for pos in states]\n",
    "    display(\n",
    "        html_print(f'trc {idx}:&nbsp;&nbsp;&nbsp;' + ''.join(''.join(x) for x in zip(obs, actions)) + '\\n')\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = World(\n",
    "    dim=3,\n",
    "    start=State(x=3, y=1),\n",
    "    overlay={\n",
    "      (1, 1): 'yellow',\n",
    "      (1, 2): 'green',\n",
    "      (1, 3): 'green',\n",
    "      (2, 3): 'red',\n",
    "      (3, 2): 'blue',\n",
    "      (3, 3): 'blue',\n",
    "    }\n",
    ")\n",
    "\n",
    "demos = [[\n",
    "   (State(3, 1), 'ego'),\n",
    "   (State(3, 1, '‚Üê'), 'env'),\n",
    "   (State(3, 2), 'ego'),\n",
    "   (State(3, 2, '‚Üê'), 'env'),\n",
    "   (State(2, 2), 'ego'),\n",
    "   (State(2, 2, '‚Üê'), 'env'),\n",
    "   (State(1, 2), 'ego'),\n",
    "   #(State(1, 2, '‚Üë'), 'env'),\n",
    "   #(State(1, 1), 'ego'),\n",
    "]]\n",
    "\n",
    "print_map(gw)\n",
    "print_trc(demos[0], gw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare against our target domain:\n",
    "\n",
    "<figure style=\"padding: 1em; background: #494949;\">\n",
    "    <img src=\"imgs/example_domain_3_2.svg\"\n",
    "         style=\"height: 20em;\"\n",
    "     />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define a set of expert demonstrations for this gridworld to guide our specification search procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some very simple base examples to warm-start our specification search process. We want to synthesize a spec that's consistent with the observed evidence thus far:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going from the partial spec to a full spec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_dfa(inputs):\n",
    "    def transition(s, c):\n",
    "        if c == 'red':\n",
    "            return s | 0b01\n",
    "        elif c == 'yellow':\n",
    "            return s | 0b10\n",
    "        return s\n",
    "\n",
    "    return dfa.DFA(\n",
    "        start=0b00,\n",
    "        inputs=inputs,\n",
    "        label=lambda s: s == 0b10,\n",
    "        transition=transition\n",
    "    )\n",
    "\n",
    "def ignore_white(path):\n",
    "    return tuple(x for x in path if x != 'white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can outline the machinery for the search process itself. We use the solution procedure in the DFA identification algorithm to synthesize a minimal DFA (in both states and non-stuttering edges) that is consistent with the observed examples to this point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fn.memoize(key_func=lambda accepting, rejecting, alphabet, order_by_stutter: hash((accepting, rejecting)))\n",
    "def find_dfas2(accepting, rejecting, alphabet, order_by_stutter):\n",
    "    dfas = find_dfas(accepting, rejecting, alphabet=alphabet, order_by_stutter=order_by_stutter)\n",
    "    dfas = fn.take(10, dfas)\n",
    "    return dfas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_check_wrapper(dfa_candidate):\n",
    "    partial = partial_dfa(dfa_candidate.inputs)\n",
    "    ce = find_subset_counterexample(dfa_candidate, partial)\n",
    "    return ce is None\n",
    "\n",
    "\n",
    "ALPHABET = frozenset({'red', 'yellow', 'blue', 'green'})\n",
    "\n",
    "base_examples = LabeledExamples(\n",
    "    positive=[\n",
    "        ('yellow',),\n",
    "        ('yellow', 'yellow'),\n",
    "    ],\n",
    "    negative=[\n",
    "        (), ('red',), ('red', 'red'),\n",
    "        ('red', 'yellow'), ('yellow', 'red'),\n",
    "        ('yellow', 'red', 'yellow'),\n",
    "        ('yellow', 'yellow', 'red'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@fn.memoize\n",
    "def subset_cegis(data):\n",
    "    global base_examples\n",
    "\n",
    "    for i in range(20):\n",
    "        mydfa = find_dfa(data.positive, data.negative, order_by_stutter=True) \n",
    "        if mydfa is None:\n",
    "            raise ConceptIdException\n",
    "        partial = partial_dfa(mydfa.inputs)\n",
    "        ce = find_subset_counterexample(mydfa, partial)\n",
    "        if ce is None:\n",
    "            break\n",
    "        base_examples @= LabeledExamples(negative=[ce])\n",
    "        data @= LabeledExamples(negative=[ce])\n",
    "\n",
    "        for k, lbl in enumerate(partial.transduce(ce)):\n",
    "            prefix = ce[:k]\n",
    "            if not lbl:\n",
    "                base_examples @= LabeledExamples(negative=[prefix])\n",
    "                data @= LabeledExamples(negative=[prefix])\n",
    "    return data\n",
    "\n",
    "\n",
    "def to_concept(data):\n",
    "    global base_examples\n",
    "    \n",
    "    data = data.map(ignore_white) @ base_examples\n",
    "    data = subset_cegis(data)\n",
    "\n",
    "    concept = DFAConcept.from_examples(\n",
    "        data, subset_check_wrapper, alphabet=ALPHABET,\n",
    "        find_dfas=find_dfas2, temp=1/4) \n",
    "    # Adjust size to account for subset information.\n",
    "    return attr.evolve(concept, size=concept.size - np.log(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diss.dfa_concept import remove_stutter\n",
    "from collections import defaultdict\n",
    "\n",
    "# adapted from the dfa library\n",
    "def get_dot(dfa_):\n",
    "    dfa_dict, init = dfa.dfa2dict(dfa_)\n",
    "    remove_stutter(dfa_dict)\n",
    "    g = pydot.Dot(rankdir=\"LR\")\n",
    "\n",
    "    nodes = {}\n",
    "    for i, (k, (v, _)) in enumerate(dfa_dict.items()):\n",
    "        shape = \"doublecircle\" if v else \"circle\"\n",
    "        nodes[k] = pydot.Node(i+1, label=f\"{k}\", shape=shape, color=\"white\", fontcolor=\"white\")\n",
    "        g.add_node(nodes[k])\n",
    "\n",
    "    edges = defaultdict(list)\n",
    "    for start, (_, transitions) in dfa_dict.items():        \n",
    "        for action, end in transitions.items():\n",
    "            color = COLOR_ALIAS[str(action)]\n",
    "            edges[start, end].append(color)\n",
    "    \n",
    "    init_node = pydot.Node(0, shape=\"point\", label=\"\", color=\"white\")\n",
    "    g.add_node(init_node)\n",
    "    g.add_edge(pydot.Edge(init_node, nodes[init], color=\"white\"))\n",
    "\n",
    "    for (start, end), colors in edges.items():\n",
    "        #color_list = f':'.join(colors)\n",
    "        #g.add_edge(pydot.Edge(nodes[start], nodes[end], color=color_list))\n",
    "        for color in colors:\n",
    "            g.add_edge(pydot.Edge(nodes[start], nodes[end], label='‚óº', fontcolor=color, color=\"white\"))\n",
    "    g.set_bgcolor(\"#002b36\")        \n",
    "    return g\n",
    "\n",
    "def view_pydot(pdot):\n",
    "    display(SVG(pdot.create_svg()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated Annealed + SGGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diss import diss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_path(path):\n",
    "    return ignore_white(map(gw.sensor, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductMC2(ProductMC):\n",
    "    def sample(self, pivot, win, attempts=20):\n",
    "        # Sample until you give a path that respects subset properties.\n",
    "        for i in range(attempts):\n",
    "            result = ProductMC.sample(self, pivot, win)\n",
    "            if win or (result is None):\n",
    "                return result\n",
    "            \n",
    "            word = lift_path(result[0])\n",
    "            if 'yellow' in word:\n",
    "                return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fn.memoize(key_func=lambda c, t, psat: c.dfa)\n",
    "def to_chain(c, t, psat):\n",
    "    chain = ProductMC.construct(\n",
    "        concept=c, tree=t, dyn=gw, max_depth=9,\n",
    "        psat=0.8, sensor=gw.sensor, xtol=0.05\n",
    "    )\n",
    "    return ProductMC2(chain.tree, chain.concept, chain.policy, chain.tree2policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iters = 25\n",
    "\n",
    "dfa_search = diss(\n",
    "    demos=demos,\n",
    "    to_concept=to_concept,\n",
    "    to_chain=to_chain,\n",
    "    competency=lambda *_: 0.8,\n",
    "    lift_path=lift_path,\n",
    "    n_iters=n_iters,\n",
    "    reset_period=5,\n",
    "    surprise_weight=20,  # Rescale surprise to make comparable to size.\n",
    "    cmf_threshold=0.99,\n",
    ")\n",
    "\n",
    "concept2energy = {}\n",
    "for _, (data, concept, metadata) in zip(trange(n_iters, desc='DISS'), dfa_search):\n",
    "    concept2energy[concept] = metadata['energy']\n",
    "    poi = metadata['poi']\n",
    "    view_pydot(get_dot(concept.dfa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_concepts = sorted(list(concept2energy), key=concept2energy.get)\n",
    "pmf = np.array([np.exp(-concept2energy[c]) for c in sorted_concepts])\n",
    "Z = pmf.sum()\n",
    "print(f'{Z=}')\n",
    "pmf /= Z\n",
    "cmf = np.cumsum(pmf)\n",
    "idx = (cmf < 0.99).sum()  # 99% of probability mass concentrated below this point.\n",
    "\n",
    "for p, c in zip(pmf, sorted_concepts[:idx + 1]):\n",
    "    print(f'prob = {p:.3}')\n",
    "    print(f'energy = {concept2energy[c]:.3}')\n",
    "    print(f'size = {c.size:.3}')\n",
    "    view_pydot(get_dot(c.dfa))\n",
    "\n",
    "# Plot CDF of distribution.\n",
    "sns.lineplot(x=list(range(len(cmf))), y=cmf)\n",
    "plt.xlabel('DFA index (sorted by probability mass)')\n",
    "plt.ylabel('CMF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compute current support's belief on unlabeled strings of interest.\n",
    "p_accept = {}\n",
    "for word in poi:\n",
    "    votes = np.array([(word in c) for c in sorted_concepts])\n",
    "    p_accept[word] = pmf @ votes\n",
    "    \n",
    "sorted_poi = sorted(poi, key=lambda x: -p_accept[x])\n",
    "\n",
    "buff = ''\n",
    "for word in sorted_poi:\n",
    "    obs = '\\n'.join(map(tile, word))\n",
    "    buff += f'{p_accept[word]:.2}:'.ljust(9, 'X').replace('X', '&nbsp')\n",
    "    buff += f'{obs}<br>'\n",
    "display(html_print(buff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepting, rejecting = set(), set()\n",
    "for word in poi:\n",
    "    belief = p_accept[word]\n",
    "    if belief > 0.9:\n",
    "        accepting.add(word)\n",
    "    elif belief < 0.1:\n",
    "        rejecting.add(word)\n",
    "data = LabeledExamples(accepting, rejecting)\n",
    "view_pydot(get_dot(to_concept(data).dfa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumeration baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler_factory(demos):\n",
    "    return GradientGuidedSampler.from_demos(\n",
    "        demos=demos,\n",
    "        to_chain=to_chain,\n",
    "        competency=lambda *_: 0.8,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_chain.invalidate_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfa.utils import minimize\n",
    "\n",
    "def enumerate_dfas():\n",
    "    data = LabeledExamples(\n",
    "        positive=[\n",
    "            ('yellow',),\n",
    "            ('yellow', 'yellow'),\n",
    "        ],\n",
    "        negative=[\n",
    "            (), ('red',), ('red', 'red'),\n",
    "            ('red', 'yellow'), ('yellow', 'red'),\n",
    "            ('yellow', 'red', 'yellow'),\n",
    "            ('yellow', 'yellow', 'red'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # CEGIS loop to add constraints to enforce subsets.\n",
    "    for i in range(20):\n",
    "        tests = fn.take(5, find_dfas(\n",
    "            data.positive,\n",
    "            data.negative,\n",
    "            order_by_stutter=True,\n",
    "            allow_unminimized=True,\n",
    "        ))\n",
    "        new_data = LabeledExamples()\n",
    "        for test in tests:\n",
    "            assert test is not None\n",
    "            partial = partial_dfa(test.inputs)\n",
    "            ce = find_subset_counterexample(test, partial)\n",
    "            if ce is not None:\n",
    "                new_data @= LabeledExamples(negative=[ce])\n",
    "        if new_data.size == 0:\n",
    "            break\n",
    "\n",
    "    dfas = find_dfas(\n",
    "        data.positive,\n",
    "        data.negative,\n",
    "        order_by_stutter=False,\n",
    "        alphabet=ALPHABET,\n",
    "        allow_unminimized=True,\n",
    "    )\n",
    "\n",
    "    yield from map(minimize, filter(subset_check_wrapper, dfas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sggs = sampler_factory(demos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Z2 = 0\n",
    "dist = Counter()\n",
    "for i, d in enumerate(fn.distinct(enumerate_dfas())):\n",
    "    concept = DFAConcept.from_dfa(d)\n",
    "    dist.update([len(d.states())])\n",
    "    print(dist)\n",
    "    print(f'             {i}                ')\n",
    "    energy = 20 * sggs(concept)[1]['surprisal'] + concept.size\n",
    "    Z2 += np.exp(-energy)\n",
    "    \n",
    "    print(f'{energy=:.3}')\n",
    "    print(f'Z2 / Z = {Z2 / Z:0.3}')\n",
    "    print('--------------------------------')\n",
    "    if i > 50:\n",
    "        break\n",
    "    #view_pydot(get_dot(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circuit + BDD based MaxEnt Policy (CAV '20)\n",
    "\n",
    "üö® üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß üö®\n",
    "\n",
    "Everything after this point of the notebook is currently under development!\n",
    "\n",
    "üö® üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß  üöß üö® "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create Dynamical System\n",
    "\n",
    "Here we create a BitVector sequential circuit, `DYN`, using `py-aiger`, the models a gridworld (line 4).\n",
    "\n",
    "Afterwords, lines 6-8 describe introducing a slip probability of `1/32` (modeled by a biased coin with bias `31/32`). \n",
    "\n",
    "**Note that states are 1-hot encoded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiger as A\n",
    "import aiger_bv as BV\n",
    "import aiger_gridworld as GW\n",
    "import aiger_ptltl as LTL\n",
    "from bidict import bidict\n",
    "from aiger_bdd import to_bdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE = BV.uatom(16, 'state')\n",
    "X = STATE[:8]\n",
    "Y = STATE[8:]\n",
    "s0 = (3, 5)\n",
    "#                            \n",
    "DYN = GW.gridworld(8, start=(s0[0], 9 - s0[1]), compressed_inputs=True)\n",
    "SLIP = BV.atom(1, 'c', signed=False).repeat(2) & BV.atom(2, 'a', signed=False)\n",
    "SLIP = SLIP.with_output('a').aigbv\n",
    "DYN <<= SLIP\n",
    "\n",
    "def encode_state(x, y):\n",
    "    x, y = x - 1, (9 - y) + 7\n",
    "    return {'state': (1 << x) | (1 << y)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Sensor / Feature overlay\n",
    "\n",
    "Next, we define the mapping from concrete states to sensor values / atomic predicates.\n",
    "We use simple coordinate wise bitvector masks to encode the color overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_test(xmask, ymask):\n",
    "    return ((X & xmask) !=0) & ((Y & ymask) != 0)\n",
    "\n",
    "\n",
    "APS = {       #            x-axis       y-axis\n",
    "    'yellow': mask_test(0b0000_0001, 0b1000_0001),\n",
    "    'blue':   mask_test(0b0000_1010, 0b0011_1100),\n",
    "    'green':  mask_test(0b0010_0000, 0b1000_0000),\n",
    "    'red':    mask_test(0b1000_0000, 0b0011_0010) \\\n",
    "            | mask_test(0b0011_1111, 0b0000_0010),\n",
    "}\n",
    "\n",
    "def create_sensor(aps):\n",
    "    sensor = BV.aig2aigbv(A.empty())\n",
    "    for name, ap in APS.items():\n",
    "        sensor |= ap.with_output(name).aigbv\n",
    "    aps = reduce(lambda x, y: x.concat(y), APS.values())\n",
    "    sensor |= (aps == 0).with_output('white').aigbv\n",
    "    return sensor\n",
    "\n",
    "SENSOR = create_sensor(APS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Overlay\n",
    "\n",
    "This can all seem pretty abstract, so let's visualize the way the sensor sees the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML as html_print\n",
    "\n",
    "\n",
    "def tile(color='black'):\n",
    "    color = COLOR_ALIAS.get(color, color)\n",
    "    s = '&nbsp;'*4\n",
    "    return f\"<text style='border: solid 1px;background-color:{color}'>{s}</text>\"\n",
    "\n",
    "\n",
    "def ap_at_state(x, y, in_ascii=False):\n",
    "    \"\"\"Use sensor to create colored tile.\"\"\"\n",
    "    state = encode_state(x, y)\n",
    "    obs = SENSOR(state)[0]   # <----------   \n",
    "    for k in COLOR_ALIAS.keys():\n",
    "        if k == 'brown':\n",
    "            continue\n",
    "        if obs[k][0]:\n",
    "            return tile(k)\n",
    "    raise NotImplementedError\n",
    "\n",
    "def print_map():\n",
    "    \"\"\"Scan the board row by row and print colored tiles.\"\"\"\n",
    "    order = range(1, 9)\n",
    "    buffer = ''\n",
    "    for y in order:\n",
    "        chars = (ap_at_state(x, y, in_ascii=True) for x in order)\n",
    "        buffer += '&nbsp;'.join(chars) + '<br>'\n",
    "    display(html_print(buffer))\n",
    "    \n",
    "DYN_SENSE = DYN >> SENSOR\n",
    "\n",
    "def encode_trace(trc):\n",
    "    actions, states = trc\n",
    "    actions = [{'a': a} for a in actions]\n",
    "    states = [encode_state(*s) for s in states]\n",
    "\n",
    "    # Fill in coin flips to mark slipping. Could use SAT solver more generally.\n",
    "    for s, a, s2 in zip([encode_state(*s0)] + states, actions, states):\n",
    "        s, s2 = GW.GridState(s['state'], 8), GW.GridState(s2['state'], 8)\n",
    "        action = a['a']\n",
    "        print(s.x, s.y)\n",
    "        print(s2.x, s2.y)\n",
    "\n",
    "        if action == GW.WEST:\n",
    "            a['c'] = 1\n",
    "        elif action == GW.EAST:\n",
    "            a['c'] = int((s2.x > s.x) or s.x == 8)\n",
    "        else:\n",
    "            a['c'] = int(s.x == s2.x)\n",
    "    actions[-1]['c'] = 1  # Last action needs some arbitrary assignment to slipping.\n",
    "    \n",
    "    return actions, states\n",
    "\n",
    "\n",
    "def lift_path(path):\n",
    "    aps = fn.pluck(0, DYN_SENSE.simulate(path))\n",
    "    aps = [fn.first(k for k, v in ap.items() if v == 1) for ap in aps]\n",
    "    print(ignore_white(aps))\n",
    "    return ignore_white(aps)\n",
    "\n",
    "\n",
    "def print_trc(trc, idx=0):\n",
    "    obs = lift_path(trc)\n",
    "    actions = [x['a'] for x in trc]\n",
    "    obs = map(tile, obs)\n",
    "    display(\n",
    "        html_print(f'trc {idx}:&nbsp;&nbsp;&nbsp;' + ''.join(''.join(x) for x in zip(actions, obs)) + '\\n')\n",
    "    )\n",
    "        \n",
    "print_map()\n",
    "\n",
    "TRC4 = [\n",
    "    {'a': '‚Üë', 'c': 0},\n",
    "    {'a': '‚Üë', 'c': 1},\n",
    "    {'a': '‚Üë', 'c': 1},\n",
    "    {'a': '‚Üí', 'c': 1},\n",
    "    {'a': '‚Üë', 'c': 1},\n",
    "    {'a': '‚Üë', 'c': 1},\n",
    "    {'a': '‚Üí', 'c': 1},\n",
    "    {'a': '‚Üí', 'c': 1},\n",
    "    {'a': '‚Üí', 'c': 1},\n",
    "    {'a': '‚Üê', 'c': 1},\n",
    "    {'a': '‚Üê', 'c': 1},\n",
    "    {'a': '‚Üê', 'c': 1},\n",
    "    {'a': '‚Üê', 'c': 1},\n",
    "    #{'a': '‚Üê', 'c': 1},\n",
    "\n",
    "]\n",
    "\n",
    "print(len(TRC4))\n",
    "\n",
    "print_trc(TRC4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_states = [{'state': x['state'].yx} for x, _ in DYN.simulate(TRC4)]\n",
    "\n",
    "for s, _ in DYN.simulate(TRC4):\n",
    "    print(s['state'].board)\n",
    "    \n",
    "test_colors = fn.lpluck(0, SENSOR.simulate(test_states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define Specification Circuits / Concept Class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiger_dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfa import DFA, dfa2dict, dict2dfa\n",
    "from functools import reduce\n",
    "\n",
    "def concept2monitor(concept):\n",
    "    # Add noop on white:\n",
    "    def transition_with_noop(s, c):\n",
    "        if c == 'white':\n",
    "            return s\n",
    "        return concept.dfa._transition(s, c)\n",
    "    \n",
    "    dfa = DFA(\n",
    "        start=concept.dfa.start,\n",
    "        outputs=concept.dfa.outputs,\n",
    "        inputs=COLOR_ALIAS,\n",
    "        label=concept.dfa._label,\n",
    "        transition=transition_with_noop,\n",
    "    )\n",
    "    dfa = attr.evolve(concept.dfa, transition=transition_with_noop, inputs=frozenset(COLOR_ALIAS))\n",
    "    circ, relabels, _ = aiger_dfa.dfa2aig(dfa)\n",
    "    # Wrap circ i/o to interface with sensor.\n",
    "    atoms = [BV.uatom(1, c) for c in COLOR_ALIAS]\n",
    "\n",
    "    # Convert input.\n",
    "    def get_idx(atom):\n",
    "        c = fn.first(atom.inputs)\n",
    "        return relabels['inputs'][c]['action'].index(True)\n",
    "\n",
    "    atoms = sorted(atoms, key=get_idx)\n",
    "    action = reduce(lambda x, y: x.concat(y), atoms).with_output('action')\n",
    "    \n",
    "    # Convert output.\n",
    "    output = BV.uatom(2, 'output')\n",
    "    for key, val in relabels['outputs'].items():\n",
    "        if val is True:\n",
    "            sat = output[key['output'].index(True)].with_output('SAT')\n",
    "    \n",
    "    monitor = action.aigbv >> circ >> sat.aigbv\n",
    "    monitor = attr.evolve(monitor, aig=monitor.aig.lazy_aig)  # HACK: force lazy evaluation.\n",
    "    return DYN >> SENSOR >> monitor, relabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating BDD game-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 15  # SAT output only depends on latch....\n",
    "causal_order = []\n",
    "for t in range(H):\n",
    "    causal_order.append(f'a##time_{t}[0]')\n",
    "    causal_order.append(f'a##time_{t}[1]')\n",
    "    causal_order.append(f'c##time_{t}[0]')\n",
    "causal_order = {x: i for i, x in enumerate(causal_order)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dd.cudd import BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = BDD()\n",
    "manager.declare(*causal_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_nx(bexpr):\n",
    "    # DFS to translate edge-compelemented BDD to networkx graph.\n",
    "    dag = nx.DiGraph()\n",
    "\n",
    "    stack, visited = [(bexpr, False, int(bexpr))], set()\n",
    "    while stack:\n",
    "        bexpr, parity, ref = stack.pop()\n",
    "\n",
    "        if ref in visited:\n",
    "            continue\n",
    "\n",
    "        visited.add(ref)\n",
    "        if bexpr in (bexpr.bdd.true, bexpr.bdd.false):\n",
    "            label = (bexpr == bexpr.bdd.true) ^ parity\n",
    "            dag.add_node(ref, label=label, level=len(bexpr.bdd.vars))\n",
    "            continue\n",
    "\n",
    "        dag.add_node(ref, label=bexpr.var, level=bexpr.level)\n",
    "\n",
    "        parity = bexpr.negated ^ parity\n",
    "        for lbl, bexpr2 in [(0, bexpr.low), (1, bexpr.high)]:\n",
    "            ref2 = int(bexpr2 if parity else ~bexpr2)\n",
    "            dag.add_edge(ref, ref2, label=lbl)\n",
    "            stack.append((bexpr2, parity, ref2))\n",
    "            \n",
    "    #TODO: Everything above this line should be upstreamed into aiger-bdd.\n",
    "            \n",
    "    for src, data in dag.nodes(data=True):\n",
    "        label = data['label']\n",
    "        if isinstance(label, bool):\n",
    "            data['kind'] = label\n",
    "        elif label.startswith('a'):\n",
    "            data['kind'] = 'ego'\n",
    "        else:\n",
    "            data['kind'] = 'env'\n",
    "\n",
    "    for src, tgt, data in dag.edges(data=True):\n",
    "        entropy = dag.nodes[tgt]['level'] - dag.nodes[src]['level'] - 1\n",
    "        entropy /= np.log2(np.e)  # Convert from base 2.\n",
    "        data['entropy'] = entropy\n",
    "    \n",
    "        if dag.nodes[src]['kind'] == 'env':\n",
    "            data['prob'] = 31/32 if data['label'] else 1/32\n",
    "    return dag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tabular Policy from BDD\n",
    "\n",
    "1. Create policy on BDD Game graph.\n",
    "2. Lift bit level policy into policy over ego and env actions (at bitvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diss import DemoPrefixTree as PrefixTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diss.tabular import TabularPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dd.cudd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_demo(trc):\n",
    "    demo = [(None, 'ego')]\n",
    "    for circ_input in trc:\n",
    "        demo.extend([\n",
    "            (circ_input['a'], 'env'),\n",
    "            (circ_input['c'], 'ego'),\n",
    "        ])\n",
    "    return demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = PrefixTree.from_demos([to_demo(TRC4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#               bdd-id    lvl   prev action  \n",
    "# Node = tuple[  int  ,   int,  int | str]   # Lifted policy state.\n",
    "\n",
    "def get_lvl(dag, node):\n",
    "    label = dag.nodes[node]['label']\n",
    "    if isinstance(label, bool):\n",
    "        return len(causal_order)\n",
    "    return causal_order[label]\n",
    "\n",
    "def get_debt(dag, node1, node2):\n",
    "    lvl1 = get_lvl(dag, node1)\n",
    "    lvl2 = get_lvl(dag, node2)\n",
    "    return lvl2 - lvl1 - 1\n",
    "\n",
    "def walk(dag, curr, bits):\n",
    "    for bit in bits:\n",
    "        yield curr\n",
    "        node, debt = curr\n",
    "        if debt > 0:  # Don't care consumes bits.\n",
    "            curr = (node, debt - 1)\n",
    "            continue\n",
    "        # Use bit for BDD transition.\n",
    "        if dag.out_degree(node) == 0:\n",
    "            import pdb; pdb.set_trace()\n",
    "        for kid in dag.neighbors(node):\n",
    "            if bit == dag.edges[node, kid]['label']:\n",
    "                break\n",
    "        curr = (kid, get_debt(dag, node, kid))\n",
    "    yield curr\n",
    "\n",
    "\n",
    "@attr.frozen\n",
    "class LiftedPolicy:\n",
    "    policy: TabularPolicy\n",
    "\n",
    "    def psat(self, node = None): return self.policy.psat(node[0])\n",
    "    def lsat(self, node = None): return self.policy.lsat(node[0])\n",
    "        \n",
    "    @property\n",
    "    def root(self):\n",
    "        return (self.policy.root, 0, None)\n",
    "\n",
    "    @staticmethod\n",
    "    def from_psat(unrolled, psat, xtol=0.5):\n",
    "        return LiftedPolicy(TabularPolicy.from_psat(unrolled, psat, xtol=xtol))\n",
    "\n",
    "    def prob(self, node, move, log = False):\n",
    "        dag = self.policy.dag\n",
    "        node1, debt1, _ = node \n",
    "        node2, debt2, action = move\n",
    "        assert (node1 != node2) or (debt1 > debt2 >= 0)\n",
    "\n",
    "        if isinstance(action, int):\n",
    "            prob = 31 / 32 if action else 1/32\n",
    "            return np.log(prob) if log else prob\n",
    "\n",
    "        action = GW.dynamics.ACTIONS_C[action]\n",
    "        bits = [action & 1, (action >> 1) & 1]\n",
    "        curr = (node1, debt1)\n",
    "        edges = fn.pairwise(walk(dag, (node1, debt1), bits))\n",
    "        \n",
    "        logp = 0\n",
    "        for start, end in edges:\n",
    "            if start[0] == end[0]:  # Don't care consumes bits.\n",
    "                logp -= np.log(2)\n",
    "            else:\n",
    "                logp += self.policy.prob(start[0], end[0], log=True)\n",
    "\n",
    "        assert end == (node2, debt2)\n",
    "        return logp if log else np.exp(logp)\n",
    "\n",
    "    def transition(self, pstate, action):\n",
    "        dag = self.policy.dag\n",
    "        if isinstance(action, str):  # action correspond to previous action.\n",
    "            bits = GW.dynamics.ACTIONS_C[action]\n",
    "            bits = [bits & 1, (bits >> 1) & 1]\n",
    "        else:\n",
    "            bits = [action]\n",
    "        node, debt = fn.last(walk(dag, pstate[:2], bits))  # QDD state.\n",
    "        return (node, debt, action)\n",
    "\n",
    "    def end_of_episode(self, pstate):\n",
    "        node, debt, _ = pstate\n",
    "        dag = self.policy.dag\n",
    "        return (debt == 0) and (dag.out_degree(node) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_path(path):\n",
    "    assert path[0] is None\n",
    "    path = path[1:]\n",
    "    path = [{'a': a, 'c': c} for a, c in fn.chunks(2, path)]\n",
    "    aps = fn.pluck(0, DYN_SENSE.simulate(path))\n",
    "    aps = [fn.first(k for k, v in ap.items() if v == 1) for ap in aps]\n",
    "    return ignore_white(aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "@attr.frozen\n",
    "class CompressedMC:\n",
    "    \"\"\"Compressed Markov Chain operating with actions.\"\"\"\n",
    "    tree: PrefixTree\n",
    "    policy: LiftedPolicy\n",
    "    tree2policy: dict[int, tuple[int, int]]\n",
    "\n",
    "    @property\n",
    "    def edge_probs(self):\n",
    "        edge_probs = {}\n",
    "        for tree_edge in self.tree.tree.edges:\n",
    "            dag_edge = [self.tree2policy[s] for s in tree_edge]\n",
    "            edge_probs[tree_edge] = self.policy.prob(*dag_edge)\n",
    "        return edge_probs\n",
    "    \n",
    "    def sample(self, pivot, win, attempts=20):\n",
    "        # Sample until you give a path that respects subset properties.\n",
    "        for i in range(attempts):\n",
    "            result = self._sample(pivot, win)\n",
    "            if win or (result is None):\n",
    "                print('here', result)\n",
    "                return result\n",
    "            \n",
    "            word = lift_path(result[0])\n",
    "            if 'yellow' in word:\n",
    "                return result\n",
    "\n",
    "    def _sample(self, pivot, win):\n",
    "        policy = self.policy\n",
    "        state = self.tree2policy[pivot]\n",
    "\n",
    "        if policy.psat(state) == float(not win):\n",
    "            return None  # Impossible to realize is_sat label.\n",
    "\n",
    "        sample_prob: float = 1\n",
    "        path = list(self.tree.prefix(pivot))\n",
    "        if policy.end_of_episode(state):\n",
    "             moves = []\n",
    "        else:\n",
    "            prev_ego = isinstance(state[-1], str)\n",
    "\n",
    "            # Make sure to deviate from prefix tree at pivot.\n",
    "            actions = {0, 1} if prev_ego else set(GW.dynamics.ACTIONS_C)\n",
    "            actions -= {self.tree2policy[s][-1] for s in self.tree.tree.neighbors(pivot)}\n",
    "\n",
    "            tmp = {policy.transition(state, a) for a in actions}\n",
    "\n",
    "            moves = list(m for m in tmp if policy.psat(m) != float(not win))\n",
    "\n",
    "        if not moves:\n",
    "            return None  # Couldn't deviate\n",
    "        \n",
    "        # Sample suffix to path conditioned on win.\n",
    "        while moves:\n",
    "            # Apply bayes rule to get Pr(s' | is_sat, s).\n",
    "            priors = np.array([policy.prob(state, m) for m in moves])\n",
    "            likelihoods = np.array([policy.psat(m) for m in moves])\n",
    "            normalizer = policy.psat(state)\n",
    "\n",
    "            if not win:\n",
    "                likelihoods = 1 - likelihoods\n",
    "                normalizer = 1 - normalizer\n",
    "\n",
    "            probs =  priors * likelihoods / normalizer\n",
    "            prob, state = random.choices(list(zip(probs, moves)), probs)[0]\n",
    "            sample_prob *= prob\n",
    "\n",
    "            # Note: win/lose are strings so the below still works...\n",
    "            action = state[-1]\n",
    "            path.append(action)\n",
    "\n",
    "            if policy.end_of_episode(state):\n",
    "                moves = []\n",
    "            else:\n",
    "                prev_ego = isinstance(action, str)\n",
    "                actions = {0, 1} if prev_ego else set(GW.dynamics.ACTIONS_C)\n",
    "                moves = [policy.transition(state, a) for a in actions]\n",
    "\n",
    "        return path, sample_prob\n",
    " \n",
    "    @staticmethod\n",
    "    def construct(concept, tree, psat):\n",
    "        # 1. Compile concept: DFA -> AIG -> BDD -> Annotated DAG.\n",
    "        monitor, _ = concept2monitor(concept)\n",
    "        unrolled = monitor.aigbv.cone('SAT').unroll(H, only_last_outputs=True)\n",
    "        manager = BDD()\n",
    "        manager.declare(*causal_order)\n",
    "        bexpr, *_ = to_bdd(unrolled, manager=manager, renamer=lambda _, x: x, levels=causal_order)\n",
    "        dag = to_nx(bexpr)\n",
    "        \n",
    "        # 2. Fit (lifted) MaxEntPolicy.\n",
    "        policy = LiftedPolicy.from_psat(dag, psat=psat)\n",
    "        \n",
    "        # 3. Need to associcate each tree stree with a policy state.\n",
    "        stack = [(tree.root, policy.root)]\n",
    "        tree2policy = {}\n",
    "        while stack:\n",
    "            tstate, pstate = stack.pop()\n",
    "            tree2policy[tstate] = pstate\n",
    "\n",
    "            # Compute local mapping from dynamics transition to next pstate.\n",
    "            #move = {s[0]: s for s in policy.dag.neighbors(pstate)}\n",
    "            for tstate2 in tree.tree.neighbors(tstate):\n",
    "                action = tree.state(tstate2)  # tree states are next actions.\n",
    "                pstate2 = policy.transition(pstate, action)\n",
    "                stack.append((tstate2, pstate2))\n",
    "        return CompressedMC(tree, policy, tree2policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISS + BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_concept2(data):\n",
    "    global base_examples\n",
    "    \n",
    "    # HACK to enforce ignoring violations of partial knowledge.\n",
    "    pos = [x for x in data.positive if 'yellow' in x] \n",
    "    neg = [x for x in data.negative if 'red' not in x]   \n",
    "    \n",
    "    # Adjust size to account for subset information.\n",
    "    return to_concept(LabeledExamples(pos, neg))\n",
    "\n",
    "\n",
    "@fn.memoize(key_func=lambda c, t, psat: c.dfa)\n",
    "def to_chain(c, t, psat):\n",
    "    chain = CompressedMC.construct(concept=c, tree=t, psat=psat)\n",
    "    return chain\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 20\n",
    "\n",
    "dfa_search = diss(\n",
    "    demos=[to_demo(TRC4)],\n",
    "    to_concept=to_concept2,\n",
    "    to_chain=to_chain,\n",
    "    competency=lambda *_: 0.8,\n",
    "    lift_path=lambda x: lift_path(x),\n",
    "    n_iters=n_iters,\n",
    "    reset_period=4,\n",
    "    surprise_weight=1,  # Rescale surprise to make comparable to size.\n",
    "    cmf_threshold=0.99,\n",
    ")\n",
    "\n",
    "concept2energy2 = {}\n",
    "for _, (data, concept, metadata) in zip(trange(n_iters, desc='DISS'), dfa_search):\n",
    "    concept2energy2[concept] = metadata['energy']\n",
    "    print(data)\n",
    "    print(metadata['energy'])\n",
    "    poi = metadata['poi']\n",
    "    view_pydot(get_dot(concept.dfa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_concepts = sorted(list(concept2energy2), key=concept2energy2.get)\n",
    "pmf = np.array([np.exp(-concept2energy2[c]) for c in sorted_concepts])\n",
    "Z = pmf.sum()\n",
    "print(f'{Z=}')\n",
    "pmf /= Z\n",
    "cmf = np.cumsum(pmf)\n",
    "idx = (cmf < 0.99).sum()  # 99% of probability mass concentrated below this point.\n",
    "\n",
    "for p, c in zip(pmf, sorted_concepts[:idx + 1]):\n",
    "    print(f'prob = {p:.3}')\n",
    "    print(f'energy = {concept2energy2[c]:.3}')\n",
    "    print(f'size = {c.size:.3}')\n",
    "    view_pydot(get_dot(c.dfa))\n",
    "\n",
    "# Plot CDF of distribution.\n",
    "sns.lineplot(x=list(range(len(cmf))), y=cmf)\n",
    "plt.xlabel('DFA index (sorted by probability mass)')\n",
    "plt.ylabel('CMF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4. Compute current support's belief on unlabeled strings of interest.\n",
    "p_accept = {}\n",
    "for word in poi:\n",
    "    votes = np.array([(word in c) for c in sorted_concepts])\n",
    "    p_accept[word] = pmf @ votes\n",
    "    \n",
    "sorted_poi = sorted(poi, key=lambda x: -p_accept[x])\n",
    "\n",
    "buff = ''\n",
    "for word in sorted_poi:\n",
    "    obs = '\\n'.join(map(tile, word))\n",
    "    buff += f'{p_accept[word]:.2}:'.ljust(9, 'X').replace('X', '&nbsp')\n",
    "    buff += f'{obs}<br>'\n",
    "display(html_print(buff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepting, rejecting = set(), set()\n",
    "for word in poi:\n",
    "    belief = p_accept[word]\n",
    "    if belief > 0.9:\n",
    "        accepting.add(word)\n",
    "    elif belief < 0.1:\n",
    "        rejecting.add(word)\n",
    "data = LabeledExamples(accepting, rejecting)\n",
    "view_pydot(get_dot(to_concept(data).dfa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
